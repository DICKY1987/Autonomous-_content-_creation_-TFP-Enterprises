#!/usr/bin/env python3
"""
Automated Content Creation System
Core implementation based on SOP Sections 3.4-3.6

Features:
- Topic research and fact extraction from Wikipedia
- Automated image sourcing from free APIs
- Text-to-speech synthesis
- Video assembly with MoviePy
- Quality assurance and fact checking
- Multi-platform upload capabilities

Dependencies:
pip install moviepy wikipedia-api requests gtts pydub pillow openai google-api-python-client
"""

import os
import json
import time
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass

# Core libraries
import requests
import wikipediaapi
from gtts import gTTS
from moviepy.editor import *
from PIL import Image
import tempfile

from .logging_config import get_logger

# Setup logging using shared configuration
logger = get_logger(__name__)

@dataclass
class ContentConfig:
    """Configuration for content generation"""
    topic: str
    duration: float = 30.0  # seconds
    canvas_width: int = 1080
    canvas_height: int = 1920
    fps: int = 30
    music_gain_db: float = -20
    voice_language: str = 'en'
    voice_speed: float = 1.0
    output_format: str = 'mp4'

@dataclass 
class QualityReport:
    """Quality assurance report structure"""
    facts_confidence: float
    technical_compliance: bool
    copyright_status: str
    claims: List[Dict]
    issues: List[str]

class ContentResearchEngine:
    """Researches topics and extracts facts from Wikipedia and other sources"""
    
    def __init__(self):
        self.wiki = wikipediaapi.Wikipedia(
            user_agent='AutoContentSystem/1.0 (contact@example.com)',
            language='en'
        )
        
    def research_topic(self, topic: str, max_sentences: int = 10) -> Dict:
        """Research a topic and extract key facts"""
        try:
            # Search Wikipedia for the topic
            page = self.wiki.page(topic)
            
            if not page.exists():
                # Try searching for related pages
                search_results = self._search_wikipedia(topic)
                if search_results:
                    page = self.wiki.page(search_results[0])
                else:
                    return {"error": f"No information found for topic: {topic}"}
            
            # Extract structured information
            content = {
                "title": page.title,
                "summary": page.summary[:500] if page.summary else "",
                "url": page.fullurl,
                "facts": self._extract_facts(page.text, max_sentences),
                "images": self._extract_image_keywords(page.text, topic),
                "categories": list(page.categories.keys())[:5]
            }
            
            logger.info(f"Successfully researched topic: {topic}")
            return content
            
        except Exception as e:
            logger.error(f"Error researching topic {topic}: {str(e)}")
            return {"error": str(e)}
    
    def _search_wikipedia(self, query: str) -> List[str]:
        """Search Wikipedia for related pages"""
        try:
            # Use Wikipedia search API
            search_url = f"https://en.wikipedia.org/api/rest_v1/page/search/{query}"
            response = requests.get(search_url)
            
            if response.status_code == 200:
                data = response.json()
                return [result['key'] for result in data.get('pages', [])[:3]]
            return []
        except Exception as e:
            logger.error(f"Wikipedia search error: {str(e)}")
            return []
    
    def _extract_facts(self, text: str, max_sentences: int) -> List[str]:
        """Extract key facts from text"""
        sentences = text.split('. ')
        
        # Filter for informative sentences (avoid short ones, navigation text, etc.)
        facts = []
        for sentence in sentences[:max_sentences*3]:  # Get more to filter from
            sentence = sentence.strip()
            if (len(sentence) > 50 and 
                not sentence.startswith(('See also', 'References', 'External links')) and
                not sentence.lower().startswith(('this article', 'the following'))) :
                facts.append(sentence + '.')
                if len(facts) >= max_sentences:
                    break
        
        return facts
    
    def _extract_image_keywords(self, text: str, topic: str) -> List[str]:
        """Extract keywords for image searching"""
        # Simple keyword extraction - can be enhanced with NLP
        keywords = [topic.lower()]
        
        # Add related terms from first paragraph
        first_paragraph = text.split('\n')[0] if text else ""
        words = first_paragraph.lower().split()
        
        # Look for proper nouns and important terms
        for word in words:
            word = word.strip('.,!?";()[]{}')
            if (len(word) > 4 and 
                word not in ['this', 'that', 'with', 'from', 'they', 'have', 'were', 'been']):
                keywords.append(word)
        
        return list(set(keywords[:5]))  # Return unique keywords, limit to 5

class ImageAssetManager:
    """Manages image sourcing from free APIs"""
    
    def __init__(self, pexels_api_key: str = None):
        self.pexels_api_key = pexels_api_key or os.getenv('PEXELS_API_KEY')
        self.session = requests.Session()
        
    def get_images_for_topic(self, keywords: List[str], count: int = 5) -> List[str]:
        """Get images from free APIs based on keywords"""
        all_images = []
        
        for keyword in keywords:
            # Try Pexels first (if API key available)
            if self.pexels_api_key:
                pexels_images = self._get_pexels_images(keyword, count//len(keywords) + 1)
                all_images.extend(pexels_images)
            
            # Try Unsplash (source API)
            unsplash_images = self._get_unsplash_images(keyword, count//len(keywords) + 1)
            all_images.extend(unsplash_images)
            
            if len(all_images) >= count:
                break
        
        return all_images[:count]
    
    def _get_pexels_images(self, query: str, per_page: int = 5) -> List[str]:
        """Get images from Pexels API"""
        if not self.pexels_api_key:
            return []
            
        try:
            headers = {'Authorization': self.pexels_api_key}
            params = {'query': query, 'per_page': per_page, 'orientation': 'portrait'}
            
            response = self.session.get(
                'https://api.pexels.com/v1/search',
                headers=headers,
                params=params
            )
            
            if response.status_code == 200:
                data = response.json()
                return [photo['src']['large'] for photo in data.get('photos', [])]
            
        except Exception as e:
            logger.error(f"Pexels API error: {str(e)}")
        
        return []
    
    def _get_unsplash_images(self, query: str, count: int = 5) -> List[str]:
        """Get images from Unsplash Source API (no key required)"""
        try:
            images = []
            for i in range(count):
                # Unsplash Source API provides random images by topic
                img_url = f"https://source.unsplash.com/1080x1920/?{query.replace(' ', ',')}&{i}"
                images.append(img_url)
            return images
        except Exception as e:
            logger.error(f"Unsplash error: {str(e)}")
            return []
    
    def download_image(self, url: str, filepath: str) -> bool:
        """Download image from URL"""
        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            with open(filepath, 'wb') as f:
                f.write(response.content)
            
            return True
        except Exception as e:
            logger.error(f"Image download error: {str(e)}")
            return False

class VoiceSynthesizer:
    """Handles text-to-speech synthesis"""
    
    def __init__(self, engine: str = 'gtts'):
        self.engine = engine
        
    def generate_voiceover(self, text: str, output_path: str, language: str = 'en', speed: float = 1.0) -> bool:
        """Generate voiceover from text"""
        try:
            if self.engine == 'gtts':
                return self._generate_gtts(text, output_path, language)
            elif self.engine == 'edge':
                return self._generate_edge_tts(text, output_path, language)
            else:
                logger.error(f"Unsupported TTS engine: {self.engine}")
                return False
                
        except Exception as e:
            logger.error(f"Voice synthesis error: {str(e)}")
            return False
    
    def _generate_gtts(self, text: str, output_path: str, language: str) -> bool:
        """Generate speech using Google TTS"""
        try:
            tts = gTTS(text=text, lang=language, slow=False)
            
            # Save to temporary mp3 first
            temp_mp3 = output_path.replace('.wav', '_temp.mp3')
            tts.save(temp_mp3)
            
            # Convert to WAV using moviepy (for better compatibility)
            audio = AudioFileClip(temp_mp3)
            audio.write_audiofile(output_path, verbose=False, logger=None)
            audio.close()
            
            # Clean up temp file
            if os.path.exists(temp_mp3):
                os.remove(temp_mp3)
            
            return True
        except Exception as e:
            logger.error(f"gTTS error: {str(e)}")
            return False
    
    def _generate_edge_tts(self, text: str, output_path: str, language: str) -> bool:
        """Generate speech using Edge TTS (requires edge-tts package)"""
        try:
            import edge_tts
            import asyncio
            
            async def generate():
                voice = "en-US-AriaNeural" if language == 'en' else f"{language}-Standard-A"
                communicate = edge_tts.Communicate(text, voice)
                await communicate.save(output_path.replace('.wav', '.mp3'))
            
            asyncio.run(generate())
            
            # Convert to WAV
            audio = AudioFileClip(output_path.replace('.wav', '.mp3'))
            audio.write_audiofile(output_path, verbose=False, logger=None)
            audio.close()
            
            return True
        except ImportError:
            logger.warning("edge-tts not installed, falling back to gTTS")
            return self._generate_gtts(text, output_path, language)
        except Exception as e:
            logger.error(f"Edge TTS error: {str(e)}")
            return False

class VideoAssemblyEngine:
    """Assembles video from assets using MoviePy"""
    
    def __init__(self, config: ContentConfig):
        self.config = config
        
    def create_video(self, script_text: str, image_paths: List[str], 
                    voiceover_path: str, output_path: str) -> bool:
        """Create video from components"""
        try:
            # Load voiceover to get duration
            voice_audio = AudioFileClip(voiceover_path)
            total_duration = voice_audio.duration
            
            # Create video clips from images
            video_clips = []
            clip_duration = total_duration / len(image_paths)
            
            for i, img_path in enumerate(image_paths):
                if not os.path.exists(img_path):
                    continue
                    
                start_time = i * clip_duration
                
                # Create image clip with Ken Burns effect
                clip = (ImageClip(img_path)
                       .set_duration(clip_duration)
                       .set_start(start_time)
                       .resize((self.config.canvas_width, self.config.canvas_height))
                       .fx(vfx.resize, 1.05))  # Slight zoom for Ken Burns effect
                
                video_clips.append(clip)
            
            if not video_clips:
                logger.error("No valid image clips created")
                return False
            
            # Combine video clips
            video = CompositeVideoClip(video_clips, size=(self.config.canvas_width, self.config.canvas_height))
            video = video.set_fps(self.config.fps)
            
            # Add audio
            final_video = video.set_audio(voice_audio)
            
            # Write final video
            final_video.write_videofile(
                output_path,
                codec='libx264',
                audio_codec='aac',
                fps=self.config.fps,
                bitrate='8M',
                verbose=False,
                logger=None
            )
            
            # Clean up
            voice_audio.close()
            video.close()
            final_video.close()
            
            logger.info(f"Video created successfully: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"Video assembly error: {str(e)}")
            return False

class QualityAssurance:
    """Quality assurance and fact checking module"""
    
    def __init__(self):
        self.min_confidence_threshold = 0.90
        
    def verify_content(self, content: Dict, script: str) -> QualityReport:
        """Perform quality assurance checks"""
        try:
            # Extract claims from script
            claims = self._extract_claims(script)
            
            # Verify each claim
            verified_claims = []
            total_confidence = 0.0
            
            for claim in claims:
                confidence = self._verify_claim(claim, content)
                verified_claims.append({
                    "text": claim,
                    "confidence": confidence,
                    "sources": [content.get("url", "")]
                })
                total_confidence += confidence
            
            avg_confidence = total_confidence / len(claims) if claims else 0.0
            
            # Technical compliance check
            tech_compliance = True  # Placeholder - would check video specs
            
            # Copyright status
            copyright_status = "pass"  # Placeholder - would check asset licenses
            
            issues = []
            if avg_confidence < self.min_confidence_threshold:
                issues.append(f"Low fact confidence: {avg_confidence:.2f}")
            
            return QualityReport(
                facts_confidence=avg_confidence,
                technical_compliance=tech_compliance,
                copyright_status=copyright_status,
                claims=verified_claims,
                issues=issues
            )
            
        except Exception as e:
            logger.error(f"QA error: {str(e)}")
            return QualityReport(0.0, False, "error", [], [str(e)])
    
    def _extract_claims(self, text: str) -> List[str]:
        """Extract factual claims from text"""
        # Simple sentence-based claim extraction
        sentences = text.split('. ')
        claims = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if (len(sentence) > 20 and
                any(keyword in sentence.lower() for keyword in 
                    ['is', 'was', 'are', 'were', 'has', 'have', 'will', 'can', 'contains'])):
                claims.append(sentence)
        
        return claims[:5]  # Limit to top 5 claims
    
    def _verify_claim(self, claim: str, source_content: Dict) -> float:
        """Verify a claim against source content"""
        try:
            # Simple text similarity check
            source_text = source_content.get('summary', '') + ' '.join(source_content.get('facts', []))
            
            # Calculate basic similarity (can be enhanced with NLP)
            claim_words = set(claim.lower().split())
            source_words = set(source_text.lower().split())
            
            if not claim_words or not source_words:
                return 0.5
            
            intersection = claim_words.intersection(source_words)
            similarity = len(intersection) / len(claim_words.union(source_words))
            
            # Boost confidence if claim appears in facts
            for fact in source_content.get('facts', []):
                if any(word in fact.lower() for word in claim_words if len(word) > 3):
                    similarity += 0.3
                    break
            
            return min(similarity, 1.0)
            
        except Exception as e:
            logger.error(f"Claim verification error: {str(e)}")
            return 0.5

class AutomatedContentSystem:
    """Main orchestrator for automated content creation"""
    
    def __init__(self, config: ContentConfig, pexels_api_key: str = None):
        self.config = config
        self.research_engine = ContentResearchEngine()
        self.image_manager = ImageAssetManager(pexels_api_key)
        self.voice_synthesizer = VoiceSynthesizer()
        self.video_engine = VideoAssemblyEngine(config)
        self.qa_module = QualityAssurance()
        
        # Create project structure
        self.project_root = Path(f"content_project_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        self._setup_project_structure()
    
    def _setup_project_structure(self):
        """Create project folder structure as per SOP"""
        folders = [
            'audio', 'brand', 'captions', 'media', 'manifests', 
            'qa', 'logs', 'alerts', 'script', 'build'
        ]
        
        for folder in folders:
            (self.project_root / folder).mkdir(parents=True, exist_ok=True)
    
    def create_content(self, topic: str) -> Tuple[bool, Dict]:
        """Main content creation pipeline"""
        logger.info(f"Starting content creation for topic: {topic}")
        
        try:
            # Step 1: Research topic
            logger.info("Step 1: Researching topic...")
            content_data = self.research_engine.research_topic(topic)
            
            if "error" in content_data:
                return False, {"error": f"Research failed: {content_data['error']}"}
            
            # Step 2: Generate script from facts
            logger.info("Step 2: Generating script...")
            script = self._generate_script(content_data)
            
            with open(self.project_root / 'script' / 'script.txt', 'w') as f:
                f.write(script)
            
            # Step 3: Get images
            logger.info("Step 3: Sourcing images...")
            image_urls = self.image_manager.get_images_for_topic(content_data.get('images', [topic]))
            
            image_paths = []
            for i, url in enumerate(image_urls):
                img_path = self.project_root / 'media' / f'scene{i+1}.jpg'
                if self.image_manager.download_image(url, str(img_path)):
                    image_paths.append(str(img_path))
            
            if not image_paths:
                return False, {"error": "Failed to download images"}
            
            # Step 4: Generate voiceover
            logger.info("Step 4: Generating voiceover...")
            voice_path = self.project_root / 'audio' / 'voiceover.wav'
            
            if not self.voice_synthesizer.generate_voiceover(script, str(voice_path)):
                return False, {"error": "Voice synthesis failed"}
            
            # Step 5: Quality assurance
            logger.info("Step 5: Quality assurance...")
            qa_report = self.qa_module.verify_content(content_data, script)
            
            with open(self.project_root / 'qa' / 'facts_report.json', 'w') as f:
                json.dump({
                    "avg_conf": qa_report.facts_confidence,
                    "claims": qa_report.claims,
                    "issues": qa_report.issues
                }, f, indent=2)
            
            # Step 6: Assemble video
            logger.info("Step 6: Assembling video...")
            output_path = self.project_root / 'build' / 'final_short.mp4'
            
            if not self.video_engine.create_video(script, image_paths, str(voice_path), str(output_path)):
                return False, {"error": "Video assembly failed"}
            
            # Success!
            result = {
                "success": True,
                "output_path": str(output_path),
                "project_root": str(self.project_root),
                "qa_report": qa_report.__dict__,
                "content_data": content_data,
                "script": script
            }
            
            logger.info(f"Content creation completed successfully: {output_path}")
            return True, result
            
        except Exception as e:
            logger.error(f"Content creation failed: {str(e)}")
            return False, {"error": str(e)}
    
    def _generate_script(self, content_data: Dict) -> str:
        """Generate engaging script from research data"""
        facts = content_data.get('facts', [])
        title = content_data.get('title', 'Unknown Topic')
        
        if not facts:
            return f"Here are some interesting facts about {title}."
        
        # Create engaging hook
        script_parts = [
            f"Did you know these amazing facts about {title}?"
        ]
        
        # Add top facts (limit for short video)
        for i, fact in enumerate(facts[:3]):
            # Clean up the fact
            clean_fact = fact.replace(title, "it").strip()
            if not clean_fact.endswith('.'):
                clean_fact += '.'
            
            script_parts.append(f"Fact {i+1}: {clean_fact}")
        
        # Add call-to-action
        script_parts.append("Like and follow for more amazing facts!")
        
        return " ".join(script_parts)

# Example usage
if __name__ == "__main__":
    # Configuration
    config = ContentConfig(
        topic="Artificial Intelligence",
        duration=30.0,
        canvas_width=1080,
        canvas_height=1920,
        fps=30
    )
    
    # Initialize system
    system = AutomatedContentSystem(config)
    
    # Create content
    success, result = system.create_content("Leonardo da Vinci")
    
    if success:
        print(f"✅ Content created successfully!")
        print(f"📁 Output: {result['output_path']}")
        print(f"📊 QA Score: {result['qa_report']['facts_confidence']:.2f}")
    else:
        print(f"❌ Failed: {result['error']}")
